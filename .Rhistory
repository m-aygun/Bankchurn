str(bank_churn_lasso)
x <- model.matrix(Churn ~ ., bank_churn_lasso)[, -1]
y <- bank_churn_lasso$Churn
grid <- 10^seq(10, -2, length = 100)
lasso.mod <- glmnet(x, y, alpha = 1, lambda = grid)
coef(lasso.mod)
dim(coef(lasso.mod))
names(bank_churn_lasso)
set.seed(5)
train <- sample(1:nrow(x), nrow(x)*2/3)
test <- (-train)
y.test <- y[test]
set.seed(5)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1)
par(mfrow=c(1,1))
plot(cv.out)
bestlam <- cv.out$lambda.min
bestlam # optimale
cv.out$lambda
cv.out$lambda.1se
log(bestlam)
lasso.pred <- predict(lasso.mod, s = bestlam, newx = x[test, ])
mse_lasso <- mean((lasso.pred - y.test)^2)
mse_lasso
out <- glmnet(x, y, alpha = 1)
lasso.coef <- predict(out, type = "coefficients", s = bestlam)[1:8, ]
#print koeficienterne
lasso.coef
lasso.coef[lasso.coef != 0]
#training and test data
train <- bank_churn_fact[intrain,]
test <- bank_churn_fact[-intrain,]
view(bank_churn_fact)
names(test)
outcome <- "Churn"
#Vi så i lasso regression, hvilke variabler der ikke havde relevans, disse eksluderes
variables <- c( ".", "ClusterHC", "clusterKmeans", "HasCrCard", "NumOfProducts", "IsActiveMember")
f <- as.formula(paste(outcome,
paste(variables, collapse = " - "), sep = " ~ "))
str(bank_churn_fact)
str(bank_churn1)
# Vi fitter en logistisk regressionsmodel:
fit_logit <- glm(f, data=train, family = "binomial")
# Forudsige sandsynlighederne på træningsdataene
predictions <- predict(fit_logit, type = "response")
# Opret ROC-kurven og beregn AUC
roc_curve <- roc(train$Churn, predictions)
# Vis AUC-værdien
auc_roc <- auc(roc_curve)
print(auc_roc)
# Visualiser ROC-kurven
roc_data <- data.frame(
specificity = rev(roc_curve$specificities),
sensitivity = rev(roc_curve$sensitivities)
)
ggplot(roc_data, aes(x = specificity, y = sensitivity)) +
geom_line(color = "blue") +
geom_abline(linetype = "dashed", color = "red") +
labs(
title = paste("ROC Curve (AUC =", round(auc_roc, 2), ")"),
x = "1 - Specificity",
y = "Sensitivity"
) +
theme_minimal()
# Foretage prædiktioner på testsættet og gemmer dem i et objekt, churn_probs:
churn_probs <- predict(fit_logit, test, type = "response")
head(churn_probs)
# Kan vi gøre det bedre end den simple model (og modellen med 50/50 split)
# Loop:
thresh <- seq(0.01, 1.0, length = 100)
omk <- rep(0, length(thresh))
for (i in 1:length(thresh)) {
glm.pred <- rep("No", length(churn_probs))
glm.pred[churn_probs>thresh[i]] <- "Yes"
glm.pred <- as.factor(glm.pred)
x <- confusionMatrix(glm.pred, test$Churn, positive = "Yes")
total <- x$table[1] + x$table[2] + x$table[3] + x$table[4]
TN <- x$table[1]/total
FP <- x$table[2]/total
FN <- x$table[3]/total
TP <- x$table[4]/total
omk[i] <- FN*FN_omk + TP*TP_omk + FP*FP_omk + TN*0
}
glm.pred <- rep("No", length(churn_probs))
glm.pred[churn_probs>0.5] <- "Yes"
glm.pred <- as.factor(glm.pred)
x <- confusionMatrix(glm.pred, test$Churn, positive = "Yes")
total <- x$table[1] + x$table[2] + x$table[3] + x$table[4]
TN <- x$table[1]/total
FP <- x$table[2]/total
FN <- x$table[3]/total
TP <- x$table[4]/total
omk_simple <- FN*FN_omk + TP*TP_omk + FP*FP_omk + TN*0
# adding a column with the propability of the customer churning based on the optimal threshold.
bank_churn_bi <- bank_churn_fact
bank_churn_bi$Log_Churn_Prob <- predict(fit_logit, newdata = bank_churn_fact, type = "response")
model <- c(rep("optimized", 100), "simple")
cost_thresh <- c(omk, omk_simple)
thresh_plot <- c(thresh, 0.5)
dataII <- data.frame(
model,
cost_thresh,
thresh_plot
)
optimized_cost <- min(dataII$cost_thresh)
threshold_0_5_cost <- subset(dataII, thresh_plot == 0.5)$cost_thresh
ggplot(dataII, aes(x = thresh_plot, y = cost_thresh, group = model, colour = model)) +
geom_line() +
geom_point() +
geom_text(data = subset(dataII, cost_thresh == optimized_cost),
aes(label = paste("(", round(thresh_plot, 2), ",", round(cost_thresh, 2), ")"),
x = thresh_plot + 0.05, y = cost_thresh),
vjust = -0.5, hjust = 0) +
geom_text(data = subset(dataII, thresh_plot == 0.5),
aes(label = paste("(", round(thresh_plot, 2), ",", round(cost_thresh, 2), ")"),
x = thresh_plot + 0.05, y = cost_thresh),
vjust = 1.5, hjust = 0)
# Vi finder først rækken, der svarer til threshold 0.5
threshold_0_5_row <- subset(dataII, thresh_plot == 0.5)
# Vi tager den første værdi af omkostningerne ved dette threshold
threshold_0_5_cost <- threshold_0_5_row$cost_thresh[1]
# Find det index, hvor omkostningen er minimal
optimal_index <- which.min(dataII$cost_thresh)
# Gem det optimale threshold og omkostningerne ved dette threshold
optimal_threshold_log <- dataII$thresh_plot[optimal_index]
optimal_cost_log <- dataII$cost_thresh[optimal_index]
# Og endelig kan vi udskrive værdierne for thrshold 0,5
print(paste("Threshold 0.5:", 0.5))
print(paste("Omkostninger ved threshold 0.5:", threshold_0_5_cost))
# Print dem ud
print(paste("Optimalt threshold:", optimal_threshold_log))
print(paste("Omkostninger ved optimalt threshold:", optimal_cost_log))
#adding a column with a binary outcome if the customer is churning based on the logistic regression optimal threshold
bank_churn_bi <- bank_churn_bi %>%
mutate(Log_Churn_Prediction = ifelse(Log_Churn_Prob > optimal_threshold_log, "Yes", "No"))
#own calculations
besparelse_mavefornemmelse <- omkostninger_mavefornemmelse - min(omk)
#total cost of own calculations
besparelse_mavefornemmelse*10000
# Indlæs pakkerne
library(MASS)
library(pROC)
library(ggplot2)
train <- bank_churn_fact[intrain,]
test <- bank_churn_fact[-intrain,]
lda.fit <- lda(f, data=train)
lda.pred <- data.frame(predict(lda.fit, test))
# Check the structure of the predicted object
str(lda.pred)
# Opret ROC-kurven og beregn AUC
roc_curve_lda <- roc(test$Churn, lda.pred$posterior.Yes)
# Vis AUC-værdien
auc_roc_lda <- auc(roc_curve_lda)
print(auc_roc_lda)
# Visualiser ROC-kurven
roc_data_lda <- data.frame(
specificity = rev(roc_curve_lda$specificities),
sensitivity = rev(roc_curve_lda$sensitivities)
)
ggplot(roc_data_lda, aes(x = specificity, y = sensitivity)) +
geom_line(color = "blue") +
geom_abline(linetype = "dashed", color = "red") +
labs(
title = paste("ROC Curve for LDA Model (AUC =", round(auc_roc_lda, 2), ")"),
x = "1 - Specificity",
y = "Sensitivity"
) +
theme_minimal()
omk_lda <- rep(0,length(thresh))
thresh <- seq(0.01, 1.0, length = 100)
results_lda <- data.frame(threshold = numeric(), cost = numeric())
# Kør for løkken for at beregne omkostningerne ved forskellige thresholds
for (i in seq_along(thresh)) {
# Skaber forudsigelser baseret på threshold
glm.pred <- ifelse(lda.pred$posterior.Yes > thresh[i], "Yes", "No")
glm.pred <- factor(glm.pred, levels = c("No", "Yes"))
# Beregn confusion matrix
cm <- confusionMatrix(glm.pred, test$Churn, positive = "Yes")
total <- sum(cm$table)
TN <- cm$table[1] / total
FP <- cm$table[2] / total
FN <- cm$table[3] / total
TP <- cm$table[4] / total
# Beregn omkostninger
cost <- FN * FN_omk + TP * TP_omk + FP * FP_omk + TN * TN_omk
# Tilføj til results_lda
results_lda <- rbind(results_lda, data.frame(threshold = thresh[i], cost = cost))
}
# Find det threshold med den laveste omkostning
optimal_threshold_lda <- results_lda$threshold[which.min(results_lda$cost)]
optimal_cost_lda <- min(results_lda$cost)
ggplot(results_lda, aes(x = threshold, y = cost)) +
geom_line() +
geom_point(data = subset(results_lda, threshold == optimal_threshold_lda),
aes(x = threshold, y = cost), color = "red", size = 3) +
geom_text(data = subset(results_lda, threshold == optimal_threshold_lda),
aes(label = paste("(", round(threshold, 2), ",", round(cost, 2), ")"),
x = threshold + 0.05, y = cost),
vjust = -0.5, hjust = 0, color = "red") +
labs(title = "Omkostninger ved forskellige thresholds for LDA",
x = "Threshold",
y = "Omkostning") +
annotate("text", x = optimal_threshold_lda, y = min(results_lda$cost),
label = paste("Threshold:", round(optimal_threshold_lda, 2)),
hjust = 1, vjust = 1, size = 5, color = "red")
lda.fit <- lda(f, data=train)
lda.pred <- predict(lda.fit, test)
# Antag, at du allerede har beregnet dit optimale threshold og gemt det i variablen optimal_threshold
# Trin 2: Generer optimal_predictions
optimal_predictions <- ifelse(lda.pred$posterior[, "Yes"] > optimal_threshold_lda, "Yes", "No")
# Trin 3: Tjek længden af optimal_predictions
print(length(optimal_predictions)) # Dette skal matche antallet af observationer i testdatasættet
print(length(test$Churn))
# Beregn forudsigelser baseret på det optimale threshold
optimal_predictions <- ifelse(lda.pred$posterior[, "Yes"] > optimal_threshold_lda, "Yes", "No")
optimal_predictions <- factor(optimal_predictions, levels = c("No", "Yes"))
bank_churn_bi$LDA_Churn_Prob <- predict(lda.fit, newdata = bank_churn_fact)$posterior[, "Yes"]
# Tilføj en ny kolonne baseret på det optimale QDA threshold
bank_churn_bi <- bank_churn_bi %>%
mutate(LDA_Churn_Prediction = ifelse(LDA_Churn_Prob > optimal_threshold_lda, "Yes", "No"))
# Beregn confusion matrix baseret på disse forudsigelser
cm <- confusionMatrix(optimal_predictions, test$Churn, positive = "Yes")
print(cm)
# Udskriv antallet af TP, FP, FN, og TN
#cat("True Positives (TP):", cm$table["Yes","Yes"], "\n")
#cat("False Positives (FP):", cm$table["No","Yes"], "\n")
#cat("False Negatives (FN):", cm$table["Yes","No"], "\n")
#cat("True Negatives (TN):", cm$table["No","No"], "\n")
#qda
# Load necessary library
library(caret)
view(bank_churn_fact)
bank_churn_fact <- as.data.frame(bank_churn_fact)
class(bank_churn_fact)
class(bank_churn_fact$IsActiveMember.0)
class(bank_churn_fact$IsActiveMember.1)
class(bank_churn_fact)
# Split data into training and test sets
set.seed(123)  # For reproducibility
intrain <- createDataPartition(bank_churn_fact$Churn, p = 0.7, list = FALSE)
train <- bank_churn_fact[intrain,]
test <- bank_churn_fact[-intrain,]
# Ensure Churn is a factor with the correct levels
train$Churn <- factor(train$Churn, levels = c("No", "Yes"))
test$Churn <- factor(test$Churn, levels = c("No", "Yes"))
# Fit QDA model
qda.fit <- qda(f, data=train)
qda.pred <- predict(qda.fit, test)
# Check the structure of the predicted posterior probabilities
str(qda.pred)
# Opret ROC-kurven og beregn AUC
roc_curve_qda <- roc(test$Churn, qda.pred$posterior[, "Yes"])
# Vis AUC-værdien
auc_roc_qda <- auc(roc_curve_qda)
print(paste("AUC for QDA model:", auc_roc_qda))
# Visualiser ROC-kurven
roc_data_qda <- data.frame(
specificity = rev(roc_curve_qda$specificities),
sensitivity = rev(roc_curve_qda$sensitivities)
)
ggplot(roc_data_qda, aes(x = specificity, y = sensitivity)) +
geom_line(color = "blue") +
geom_abline(linetype = "dashed", color = "red") +
labs(
title = paste("ROC Curve for QDA Model (AUC =", round(auc_roc_qda, 2), ")"),
x = "1 - Specificity",
y = "Sensitivity"
) +
theme_minimal()
print(length(glm.pred)) # Dette skal matche antallet af observationer i testdatasættet
print(length(test$Churn))
str(glm.pred)
head(qda.pred$posterior)
sum(is.na(qda.pred$posterior[, "Yes"]))
install.packages("DT")
glm.pred
omk_qda <- rep(0,length(thresh))
thresh <- seq(0.01, 1.0, length = 100)
results_qda <- data.frame(threshold = numeric(), cost = numeric())
# Loop to calculate costs for different thresholds
for (i in seq_along(thresh)) {
# Create predictions based on the threshold
glm.pred <- ifelse(qda.pred$posterior[, "Yes"] > thresh[i], "Yes", "No")
glm.pred <- factor(glm.pred, levels = c("No", "Yes"))
# Check lengths of predictions and test data
print(length(glm.pred)) # This should match the number of observations in the test dataset
print(length(test$Churn))
# Beregn confusion matrix
cm <- confusionMatrix(glm.pred, test$Churn, positive = "Yes")
total <- sum(cm$table)
TN <- cm$table[1] / total
FP <- cm$table[2] / total
FN <- cm$table[3] / total
TP <- cm$table[4] / total
# Beregn omkostninger
cost <- FN * FN_omk + TP * TP_omk + FP * FP_omk + TN * TN_omk
# Tilføj til results_qda
results_qda <- rbind(results_qda, data.frame(threshold = thresh[i], cost = cost))
}
# Find det threshold med den laveste omkostning
optimal_threshold_qda <- results_qda$threshold[which.min(results_qda$cost)]
optimal_cost_qda <- min(results_qda$cost)
ggplot(results_qda, aes(x = threshold, y = cost)) +
geom_line() +
geom_point(data = subset(results_qda, threshold == optimal_threshold_qda),
aes(x = threshold, y = cost), color = "red", size = 3) +
geom_text(data = subset(results_qda, threshold == optimal_threshold_qda),
aes(label = paste("(", round(threshold, 2), ",", round(cost, 2), ")"),
x = threshold + 0.05, y = cost),
vjust = -0.5, hjust = 0, color = "red") +
labs(title = "Omkostninger ved forskellige thresholds for QDA",
x = "Threshold",
y = "Omkostning") +
annotate("text", x = optimal_threshold_qda, y = min(results_qda$cost),
label = paste("Threshold:", round(optimal_threshold_qda, 2)),
hjust = 1, vjust = 1, size = 5, color = "red")
# Find det threshold med den laveste omkostning
optimal_threshold_qda <- results_qda$threshold[which.min(results_qda$cost)]
optimal_cost_qda <- min(results_qda$cost)
ggplot(results_qda, aes(x = threshold, y = cost)) +
geom_line() +
geom_point(data = subset(results_qda, threshold == optimal_threshold_qda),
aes(x = threshold, y = cost), color = "red", size = 3) +
geom_text(data = subset(results_qda, threshold == optimal_threshold_qda),
aes(label = paste("(", round(threshold, 2), ",", round(cost, 2), ")"),
x = threshold + 0.05, y = cost),
vjust = -0.5, hjust = 0, color = "red") +
labs(title = "Omkostninger ved forskellige thresholds for QDA",
x = "Threshold",
y = "Omkostning") +
annotate("text", x = optimal_threshold_qda, y = min(results_qda$cost),
label = paste("Threshold:", round(optimal_threshold_qda, 2)),
hjust = 1, vjust = 1, size = 5, color = "red")
qda.fit <- qda(f, data=train)
qda.pred <- predict(qda.fit, test)
# Trin 2: Generer optimal_predictions
optimal_predictions <- ifelse(qda.pred$posterior[, "Yes"] > optimal_threshold_qda, "Yes", "No")
# Trin 3: Tjek længden af optimal_predictions
#print(length(optimal_predictions)) # Dette skal matche antallet af observationer i testdatasættet
print(length(test$Churn))
# Beregn forudsigelser baseret på det optimale threshold
optimal_predictions <- ifelse(qda.pred$posterior[, "Yes"] > optimal_threshold_qda, "Yes", "No")
optimal_predictions <- factor(optimal_predictions, levels = c("No", "Yes"))
# Beregn confusion matrix baseret på disse forudsigelser
cm <- confusionMatrix(optimal_predictions, test$Churn, positive = "Yes")
print(cm)
bank_churn_bi$QDA_Churn_Prob <- predict(qda.fit, newdata = bank_churn_fact)$posterior[, "Yes"]
bank_churn_gbm <- bank_churn1 %>%
dplyr::select(-RowNumber, -CustomerId, -Surname) %>%
rename(Churn = Exited) %>%
mutate(Churn = factor(Churn, levels = c(0, 1)))
str(bank_churn_gbm)
library(gbm)
# Sikrer reproducerbarhed
set.seed(123)
# Oprette trænings- og testdatasæt
trainIndex <- createDataPartition(bank_churn_gbm$Churn, p = .7,
list = FALSE,
times = 1)
trainData <- bank_churn_gbm[trainIndex, ]
testData <- bank_churn_gbm[-trainIndex, ]
# Omdøb faktorniveauerne til "Class1" og "Class0"
trainData$Churn <- factor(trainData$Churn, levels = c(0, 1), labels = c("Class0", "Class1"))
# Opdater også testData, hvis du har det
testData$Churn <- factor(testData$Churn, levels = c(0, 1), labels = c("Class0", "Class1"))
# Definer et grid af parametre at prøve (kun n.trees og shrinkage)
tuneGrid <- expand.grid(.n.trees = c(100, 500, 1000),
.shrinkage = c(0.01, 0.05, 0.1),
.interaction.depth = 1,
.n.minobsinnode = 10) # Tilføjer n.minobsinnode med en værdi af 10
control <- trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary)
gbmFit <- train(Churn ~ ., data = trainData, method = "gbm",
trControl = control, verbose = FALSE,
tuneGrid = tuneGrid,
metric = "ROC",
distribution = "bernoulli")
# Se de bedste parametre
print(gbmFit$bestTune)
bank_churn_gbm <- bank_churn1 %>%
dplyr::select(-RowNumber, -CustomerId, -Surname) %>%
rename(Churn = Exited) %>%
mutate(Churn = factor(Churn, levels = c(0, 1)))
str(bank_churn_gbm)
library(gbm)
# Sikrer reproducerbarhed
set.seed(123)
# Oprette trænings- og testdatasæt
trainIndex <- createDataPartition(bank_churn_gbm$Churn, p = .7,
list = FALSE,
times = 1)
trainData <- bank_churn_gbm[trainIndex, ]
testData <- bank_churn_gbm[-trainIndex, ]
# Omdøb faktorniveauerne til "Class1" og "Class0"
trainData$Churn <- factor(trainData$Churn, levels = c(0, 1), labels = c("Class0", "Class1"))
# Opdater også testData, hvis du har det
testData$Churn <- factor(testData$Churn, levels = c(0, 1), labels = c("Class0", "Class1"))
# Definer et grid af parametre at prøve (kun n.trees og shrinkage)
tuneGrid <- expand.grid(.n.trees = c(100, 500, 1000),
.shrinkage = c(0.01, 0.05, 0.1),
.interaction.depth = 1,
.n.minobsinnode = 10) # Tilføjer n.minobsinnode med en værdi af 10
control <- trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary)
gbmFit <- train(Churn ~ ., data = trainData, method = "gbm",
trControl = control, verbose = FALSE,
tuneGrid = tuneGrid,
metric = "ROC",
distribution = "bernoulli")
# Se de bedste parametre
print(gbmFit$bestTune)
# Brug model til at lave forudsigelser
predictions <- predict(gbmFit, newdata = testData, type = "prob")
# Beregn AUC for at evaluere modellens præstation
library(pROC)
auc <- roc(testData$Churn, predictions[,2])
print(auc$auc)
plot(auc)
# Omkostningsberegning kan tilføjes her baseret på dine specifikke kriterier
# Beregn forudsagte sandsynligheder for testdatasættet
predicted_probs_gbm <- predict(gbmFit, newdata = testData, type = "prob")[,"Class1"]
# Beregn forudsagte klasser for testdatasættet ved et threshold på 0,5
predicted_class_gbm <- ifelse(predicted_probs_gbm > 0.5, "Class1", "Class0")
# Sørg for at både Predicted og Actual er faktorer med de samme niveauer
predicted_factor_gbm <- factor(predicted_class_gbm, levels = c("Class0", "Class1"))
actual_factor_gbm <- factor(testData$churn, levels = c("Class0", "Class1")) # Juster variabelnavnet efter dit datasæt
# Beregn og udskriv confusion matrix
cm <- confusionMatrix(predicted_factor_gbm, actual_factor_gbm)
# Tjek længden af predicted_factor_gbm og actual_factor_gbm
print(length(predicted_factor_gbm)) # Dette skal matche antallet af observationer i testdatasættet
print(length(actual_factor_gbm))
# Beregn forudsagte sandsynligheder for testdatasættet
predicted_probs_gbm <- predict(gbmFit, newdata = testData, type = "prob")[,"Class1"]
# Beregn forudsagte sandsynligheder for testdatasættet
predicted_probs_gbm <- predict(gbmFit, newdata = testData, type = "prob")[,"Class1"]
# Beregn forudsagte klasser for testdatasættet ved et threshold på 0,5
predicted_class_gbm <- ifelse(predicted_probs_gbm > 0.5, "Class1", "Class0")
# Sørg for at både Predicted og Actual er faktorer med de samme niveauer
predicted_factor_gbm <- factor(predicted_class_gbm, levels = c("Class0", "Class1"))
actual_factor_gbm <- factor(testData$Churn, levels = c("Class0", "Class1")) # Juster variabelnavnet efter dit datasæt
# Tjek længden af predicted_factor_gbm og actual_factor_gbm
print(length(predicted_factor_gbm)) # Dette skal matche antallet af observationer i testdatasættet
print(length(actual_factor_gbm))
# Beregn og udskriv confusion matrix
cm <- confusionMatrix(predicted_factor_gbm, actual_factor_gbm)
print(cm)
# Find det optimale threshold og de tilhørende omkostninger
optimal <- omkostninger_gbm[which.min(omkostninger_gbm$cost), ]
print(optimal)
optimal_threshold_gbm <- optimal$threshold
optimal_cost_gbm <- optimal$cost
ggplot(omkostninger_gbm, aes(x = threshold, y = cost)) +
geom_line() +
geom_point(data = optimal, aes(x = threshold, y = cost), color = "red", size = 4) +
geom_text(data = optimal,
aes(label = paste("(", round(threshold, 2), ",", round(cost, 2), ")"),
x = threshold + 0.05, y = cost),
vjust = -0.5, hjust = 0, color = "red") +
labs(title = "Omkostninger ved forskellige thresholds for GBM",
x = "Threshold",
y = "Omkostning")
# Beregn sandsynligheder for hele datasættet med din GBM-model
predicted_probs_whole_gbm <- predict(gbmFit, newdata=bank_churn_gbm, type="prob")[,2]
# Tilføjer sandsynlighederne som en kolonne i bi datasættet
bank_churn_bi$GBM_Churn_Prob <- predicted_probs_whole_gbm
# Bestem det optimale threshold fra dine tidligere resultater
optimal_threshold_gbm <- optimal$threshold  # Sørg for, at dette er opdateret baseret på GBM-resultaterne
# Generer forudsigelser baseret på det optimale threshold for hele datasættet
optimal_predictions_gbm <- ifelse(predicted_probs_whole_gbm > optimal_threshold_gbm, "Yes", "No")
# Tilføjer en kolonne, der viser om en kunde churner på baggrund af det optimale GBM threshold
bank_churn_bi <- bank_churn_bi %>%
mutate(GBM_Churn_Prediction = optimal_predictions_gbm)
setwd("C:/Users/mette/OneDrive/Skrivebord/Bankchurn")
# Beregn og udskriv confusion matrix
cm <- confusionMatrix(predicted_factor_gbm, actual_factor_gbm)
print(cm)
# Definer thresholds
thresh <- seq(0.01, 1, by = 0.01)
# Initialiser en dataframe til at holde omkostningerne ved hvert threshold
omkostninger_gbm <- data.frame(threshold = numeric(), cost = numeric())
# Loop over hvert threshold for at beregne omkostningerne
for(t in thresh) {
# Generer klassificering baseret på det aktuelle threshold
predicted_class_gbm <- ifelse(predicted_probs_gbm > t, "Class1", "Class0")
# Sørg for at både Predicted og Actual er faktorer med de samme niveauer
predicted_factor_gbm <- factor(predicted_class_gbm, levels = c("Class0", "Class1"))
actual_factor_gbm <- factor(testData$Churn, levels = c("Class0", "Class1"))
# Beregn confusion matrix
cm_gbm <- confusionMatrix(predicted_factor_gbm, actual_factor_gbm)
# Ekstraher værdier fra confusion matrix
TN_gbm <- cm_gbm$table["Class0","Class0"]
FP_gbm <- cm_gbm$table["Class1","Class0"]
FN_gbm <- cm_gbm$table["Class0","Class1"]
TP_gbm <- cm_gbm$table["Class1","Class1"]
# Beregn omkostningerne
cost_gbm <- (FN_gbm * FN_omk + TP_gbm * TP_omk + FP_gbm * FP_omk + TN_gbm * TN_omk) / sum(cm_gbm$table)
# Tilføj threshold og omkostninger til dataframe
omkostninger_gbm <- rbind(omkostninger_gbm, data.frame(threshold = t, cost = cost_gbm))
}
# Find det optimale threshold og de tilhørende omkostninger
optimal <- omkostninger_gbm[which.min(omkostninger_gbm$cost), ]
print(optimal)
optimal_threshold_gbm <- optimal$threshold
optimal_cost_gbm <- optimal$cost
ggplot(omkostninger_gbm, aes(x = threshold, y = cost)) +
geom_line() +
geom_point(data = optimal, aes(x = threshold, y = cost), color = "red", size = 4) +
geom_text(data = optimal,
aes(label = paste("(", round(threshold, 2), ",", round(cost, 2), ")"),
x = threshold + 0.05, y = cost),
vjust = -0.5, hjust = 0, color = "red") +
labs(title = "Omkostninger ved forskellige thresholds for GBM",
x = "Threshold",
y = "Omkostning")
