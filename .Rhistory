nvmax = 19)
for (i in 1:16) { # her gennemløbes alle kandidatmodeller
pred <- predict(best.fit, KAG_train[folds == j, ], id = i)
# predict-funktionen ovenfor kalder den funktion, vi har lavet tidligere.
cv.errors[j, i] <-
mean((KAG_train$ROAS[folds == j] - pred)^2) # Her udregnes MSE for hver
# fold for hver kandidatmodel
}
}
for (j in 1:k) { # her gennemløbes alle folds
best.fit <- regsubsets(ROAS ~ .,
data = KAG_train[folds != j, ],
nvmax = 19)
for (i in 1:19) { # her gennemløbes alle kandidatmodeller
pred <- predict(best.fit, KAG_train[folds == j, ], id = i)
# predict-funktionen ovenfor kalder den funktion, vi har lavet tidligere.
cv.errors[j, i] <-
mean((KAG_train$ROAS[folds == j] - pred)^2) # Her udregnes MSE for hver
# fold for hver kandidatmodel
}
}
set.seed(123)
folds <- sample(rep(1:k, length = n)) #Vi tildeler en værdi mellem 1 og n
dim(KAG_train)[2]  # Der er 20 variabler og dermed 19 prædiktorer
cv.errors <- matrix(NA, k, 19,
dimnames = list(NULL, paste(1:19)))
cv.errors
for (j in 1:k) { # her gennemløbes alle folds
best.fit <- regsubsets(ROAS ~ .,
data = KAG_train[folds != j, ],
nvmax = 19)
for (i in 1:19) { # her gennemløbes alle kandidatmodeller
pred <- predict(best.fit, KAG_train[folds == j, ], id = i)
# predict-funktionen ovenfor kalder den funktion, vi har lavet tidligere.
cv.errors[j, i] <-
mean((KAG_train$ROAS[folds == j] - pred)^2) # Her udregnes MSE for hver
# fold for hver kandidatmodel
}
}
str(KAG_bts)
# Erstat NaN og Inf værdier med NA
KAG_bts[KAG_bts == Inf | is.nan(KAG_bts)] <- NA
# Erstat NaN og Inf værdier med NA
KAG_bts[KAG_bts == Inf | is.nan(KAG_bts)] <- NA
library(dplyr)
# Erstat Inf og NaN med NA i hele datasættet
KAG_bts <- KAG_bts %>%
mutate(across(everything(), ~replace(., . == Inf | is.nan(.), NA)))
# Erstat NaN og Inf værdier med NA
KAG_bts[KAG_bts == Inf | is.nan(KAG_bts)] <- NA
x <- model.matrix(ROAS ~ ., KAG_bts)[, -1]
y <- KAG_bts$ROAS
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*2/3)
test <- (-train)
y.test <- y[test]
#best subset
predict.regsubsets <- function(object, newdata, id, ...) {
form <- as.formula(object$call[[2]])
mat <- model.matrix(form, newdata)
coefi <- coef(object, id = id)
xvars <- names(coefi)
mat[, xvars] %*% coefi
}
KAG_train <- KAG_bts[train,]
KAG_test <- KAG_bts[test,]
k <- 10 # Vi danner 10 folds
n <- nrow(KAG_bts) # registrerer hvor mange observationer, vi har.
set.seed(123)
folds <- sample(rep(1:k, length = n)) #Vi tildeler en værdi mellem 1 og n
dim(KAG_train)[2]  # Der er 20 variabler og dermed 19 prædiktorer
cv.errors <- matrix(NA, k, 19,
dimnames = list(NULL, paste(1:19)))
cv.errors
str(KAG_bts)
for (j in 1:k) { # her gennemløbes alle folds
best.fit <- regsubsets(ROAS ~ .,
data = KAG_train[folds != j, ],
nvmax = 19)
for (i in 1:19) { # her gennemløbes alle kandidatmodeller
pred <- predict(best.fit, KAG_train[folds == j, ], id = i)
# predict-funktionen ovenfor kalder den funktion, vi har lavet tidligere.
cv.errors[j, i] <-
mean((KAG_train$ROAS[folds == j] - pred)^2) # Her udregnes MSE for hver
# fold for hver kandidatmodel
}
}
class(KAG_bts)
pacman::p_load(DataExplorer, tidyverse, tidymodels, caret, leaps, ISLR2,
corrplot, mgcv)
KAG_conversion_data <- read.csv("data/KAG_conversion_data.csv")
glimpse(KAG_conversion_data)
# names(KAG_conversion_data)
KAG_conversion_data  <- KAG_conversion_data |>
mutate(CTR = round((Clicks / Impressions) * 100, 4),
CPC = round(Spent / Clicks, 2)
)
# names(KAG_conversion_data)
KAG_conversion_data  <- KAG_conversion_data |>
mutate(totConv = Total_Conversion + Approved_Conversion,
conVal = Total_Conversion * 5,
appConVal = Approved_Conversion * 100,
totConVal = conVal + appConVal,
costPerCon = round(Spent / totConv, 2),
ROAS = round(totConVal / Spent, 2),
CPM = round(Spent/Impressions * 1000, 2)
)
# Beslut mellem imputation eller sletning af missing værdier
dim(KAG_conversion_data)
table(is.na(KAG_conversion_data))
summary(KAG_conversion_data)
plot_missing(KAG_conversion_data)
KAG_conversion_data_nomiss = na.omit(KAG_conversion_data)
# Ved at dividere med nul (se beregninger ovenfor) kan Inf værdier fremkomme;
KAG_conversion_data_nomiss$costPerCon <-
ifelse(KAG_conversion_data_nomiss$costPerCon == Inf, 0,
KAG_conversion_data_nomiss$costPerCon)
summary(KAG_conversion_data_nomiss$costPerCon)
KAG_conversion_data_nomiss$appConVal =
as.numeric(KAG_conversion_data_nomiss$appConVal)
KAG_conversion_data_nomiss$Total_Conversion =
as.numeric(KAG_conversion_data_nomiss$Total_Conversion)
KAG_conversion_data_nomiss$Impressions =
as.numeric(KAG_conversion_data_nomiss$Impressions)
KAG_conversion_data_nomiss$Clicks =
as.numeric(KAG_conversion_data_nomiss$Clicks)
KAG_conversion_data_nomiss$totConv =
as.numeric(KAG_conversion_data_nomiss$totConv)
KAG_conversion_data_nomiss$xyz_campaign_id =
as.factor(KAG_conversion_data_nomiss$xyz_campaign_id)
KAG_conversion_data_nomiss$gender =
as.factor(KAG_conversion_data_nomiss$gender)
KAG_conversion_data_nomiss$age =
as.factor(KAG_conversion_data_nomiss$age)
str(KAG_conversion_data_nomiss)
options(repr.plot.width=4, repr.plot.height=4)
plot_bar(KAG_conversion_data_nomiss)
plot_histogram(KAG_conversion_data_nomiss)
# Outliers
par(mfrow=c(1,1))
attach(KAG_conversion_data_nomiss)
options(repr.plot.width=4, repr.plot.height=4)
plot_bar(KAG_conversion_data_nomiss)
plot_histogram(KAG_conversion_data_nomiss)
# Overvej hvilke metoder fra kapitel 7, man kan anvende på disse data.
```
# Outliers
par(mfrow=c(1,1))
attach(KAG_conversion_data_nomiss)
# ROAS
boxplot(ROAS)
boxplot(ROAS)$out
# Her tildeler jeg outliers til en vektor og fjerner dem
outliers <- boxplot(ROAS, plot=FALSE)$out
# fjerner rækker der indeholder outliers
KAG_conversion_data_nomiss_nooutliers <-
KAG_conversion_data_nomiss[-which(ROAS %in% outliers),]
boxplot(KAG_conversion_data_nomiss_nooutliers$ROAS)
# Der eksisterer alternative måder at behandle outliers.
# Okay, nu er navnet blevet for langt:)
KAG_bts <-
KAG_conversion_data_nomiss_nooutliers
# Der eksisterer alternative måder at behandle outliers.
# Okay, nu er navnet blevet for langt:)
KAG_bts <-
KAG_conversion_data_nomiss_nooutliers
```{r }
pairs(KAG_bts)
glimpse(KAG_bts)
# eller en ad gangen
ggplot(KAG_bts, aes(xyz_campaign_id, ROAS)) +
stat_summary(fun.y="mean", geom="bar")
ggplot(KAG_bts, aes(age, ROAS)) +
stat_summary(fun.y="mean", geom="bar")
ggplot(KAG_bts, aes(gender, ROAS)) +
stat_summary(fun.y="mean", geom="bar")
ggplot(KAG_bts, aes(interest, ROAS)) +
stat_summary(fun.y="mean", geom="bar")
ggplot(KAG_bts, aes(Spent, ROAS)) +
geom_point() +
labs(x = "Omkostninger på kampagne", y = "ROAS")
options(repr.plot.width=6, repr.plot.height=3)
ggplot(KAG_bts, aes(Spent, totConv)) +
geom_point() +
labs(x = "Omkostninger på kampagne", y = "Total konverteringer")
names(KAG_bts)
KAG_bts
```{r eval=FALSE}
# Measure of associations
par(mfrow = c(1, 1))
cormatrix = corrplot(cor(KAG_bts [, -c(1:6)]))
# eller
cor(KAG_bts[,-c(1:6)],KAG_bts$ROAS)
# Measure of associations
par(mfrow = c(1, 1))
cormatrix = corrplot(cor(KAG_bts [, -c(1:6)]))
# eller
cor(KAG_bts[,-c(1:6)],KAG_bts$ROAS)
View(KAG_bts)
KAG_bts <- KAG_bts %>% select(ROAS, everything())
x <- model.matrix(ROAS ~ ., KAG_bts)[, -1]
y <- KAG_bts$ROAS
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*2/3)
test <- (-train)
y.test <- y[test]
#best subset
predict.regsubsets <- function(object, newdata, id, ...) {
form <- as.formula(object$call[[2]])
mat <- model.matrix(form, newdata)
coefi <- coef(object, id = id)
xvars <- names(coefi)
mat[, xvars] %*% coefi
}
KAG_train <- KAG_bts[train,]
View(KAG_train)
KAG_test <- KAG_bts[test,]
View(KAG_test)
k <- 10 # Vi danner 10 folds
n <- nrow(KAG_bts) # registrerer hvor mange observationer, vi har.
set.seed(123)
folds <- sample(rep(1:k, length = n)) #Vi tildeler en værdi mellem 1 og n
dim(KAG_train)[2]  # Der er 20 variabler og dermed 19 prædiktorer
cv.errors <- matrix(NA, k, 19,
dimnames = list(NULL, paste(1:19)))
cv.errors
str(KAG_bts)
library(dplyr)
for (j in 1:k) { # her gennemløbes alle folds
best.fit <- regsubsets(ROAS ~ .,
data = KAG_train[folds != j, ],
nvmax = 19)
for (i in 1:19) { # her gennemløbes alle kandidatmodeller
pred <- predict(best.fit, KAG_train[folds == j, ], id = i)
# predict-funktionen ovenfor kalder den funktion, vi har lavet tidligere.
cv.errors[j, i] <-
mean((KAG_train$ROAS[folds == j] - pred)^2) # Her udregnes MSE for hver
# fold for hver kandidatmodel
}
}
# Erstat Inf og NaN med NA i hele datasættet
KAG_bts <- KAG_bts %>%
mutate(across(everything(), ~replace(., . == Inf | is.nan(.), NA)))
# Fjern rækker med NA værdier (alternativt kan du erstatte dem)
KAG_bts_clean <- na.omit(KAG_bts)
for (j in 1:k) { # her gennemløbes alle folds
best.fit <- regsubsets(ROAS ~ .,
data = KAG_train[folds != j, ],
nvmax = 19)
for (i in 1:19) { # her gennemløbes alle kandidatmodeller
pred <- predict(best.fit, KAG_train[folds == j, ], id = i)
# predict-funktionen ovenfor kalder den funktion, vi har lavet tidligere.
cv.errors[j, i] <-
mean((KAG_train$ROAS[folds == j] - pred)^2) # Her udregnes MSE for hver
# fold for hver kandidatmodel
}
}
pacman::p_load(DataExplorer, tidyverse, tidymodels, caret, leaps, ISLR2,
corrplot, mgcv)
KAG_conversion_data <- read.csv("data/KAG_conversion_data.csv")
glimpse(KAG_conversion_data)
# names(KAG_conversion_data)
KAG_conversion_data  <- KAG_conversion_data |>
mutate(CTR = round((Clicks / Impressions) * 100, 4),
CPC = round(Spent / Clicks, 2)
)
# names(KAG_conversion_data)
KAG_conversion_data  <- KAG_conversion_data |>
mutate(totConv = Total_Conversion + Approved_Conversion,
conVal = Total_Conversion * 5,
appConVal = Approved_Conversion * 100,
totConVal = conVal + appConVal,
costPerCon = round(Spent / totConv, 2),
ROAS = round(totConVal / Spent, 2),
CPM = round(Spent/Impressions * 1000, 2)
)
# Beslut mellem imputation eller sletning af missing værdier
dim(KAG_conversion_data)
table(is.na(KAG_conversion_data))
summary(KAG_conversion_data)
plot_missing(KAG_conversion_data)
KAG_conversion_data_nomiss = na.omit(KAG_conversion_data)
# Ved at dividere med nul (se beregninger ovenfor) kan Inf værdier fremkomme;
KAG_conversion_data_nomiss$costPerCon <-
ifelse(KAG_conversion_data_nomiss$costPerCon == Inf, 0,
KAG_conversion_data_nomiss$costPerCon)
summary(KAG_conversion_data_nomiss$costPerCon)
View(KAG_conversion_data_nomiss)
# Outliers
par(mfrow=c(1,1))
attach(KAG_conversion_data_nomiss)
KAG_bts <- KAG_bts %>% select(ROAS, everything())
x <- model.matrix(ROAS ~ ., KAG_bts)[, -1]
y <- KAG_bts$ROAS
pacman::p_load(DataExplorer, tidyverse, tidymodels, caret, leaps, ISLR2,
corrplot, mgcv)
KAG_conversion_data <- read.csv("data/KAG_conversion_data.csv")
glimpse(KAG_conversion_data)
# names(KAG_conversion_data)
KAG_conversion_data  <- KAG_conversion_data |>
mutate(CTR = round((Clicks / Impressions) * 100, 4),
CPC = round(Spent / Clicks, 2)
)
# names(KAG_conversion_data)
KAG_conversion_data  <- KAG_conversion_data |>
mutate(totConv = Total_Conversion + Approved_Conversion,
conVal = Total_Conversion * 5,
appConVal = Approved_Conversion * 100,
totConVal = conVal + appConVal,
costPerCon = round(Spent / totConv, 2),
ROAS = round(totConVal / Spent, 2),
CPM = round(Spent/Impressions * 1000, 2)
)
# Beslut mellem imputation eller sletning af missing værdier
dim(KAG_conversion_data)
table(is.na(KAG_conversion_data))
summary(KAG_conversion_data)
plot_missing(KAG_conversion_data)
KAG_conversion_data_nomiss = na.omit(KAG_conversion_data)
# Ved at dividere med nul (se beregninger ovenfor) kan Inf værdier fremkomme;
KAG_conversion_data_nomiss$costPerCon <-
ifelse(KAG_conversion_data_nomiss$costPerCon == Inf, 0,
KAG_conversion_data_nomiss$costPerCon)
summary(KAG_conversion_data_nomiss$costPerCon)
KAG_conversion_data_nomiss$appConVal =
as.numeric(KAG_conversion_data_nomiss$appConVal)
KAG_conversion_data_nomiss$Total_Conversion =
as.numeric(KAG_conversion_data_nomiss$Total_Conversion)
KAG_conversion_data_nomiss$Impressions =
as.numeric(KAG_conversion_data_nomiss$Impressions)
KAG_conversion_data_nomiss$Clicks =
as.numeric(KAG_conversion_data_nomiss$Clicks)
KAG_conversion_data_nomiss$totConv =
as.numeric(KAG_conversion_data_nomiss$totConv)
KAG_conversion_data_nomiss$xyz_campaign_id =
as.factor(KAG_conversion_data_nomiss$xyz_campaign_id)
KAG_conversion_data_nomiss$gender =
as.factor(KAG_conversion_data_nomiss$gender)
KAG_conversion_data_nomiss$age =
as.factor(KAG_conversion_data_nomiss$age)
str(KAG_conversion_data_nomiss)
options(repr.plot.width=4, repr.plot.height=4)
plot_bar(KAG_conversion_data_nomiss)
plot_histogram(KAG_conversion_data_nomiss)
# Outliers
par(mfrow=c(1,1))
attach(KAG_conversion_data_nomiss)
# ROAS
boxplot(ROAS)
boxplot(ROAS)$out
# Her tildeler jeg outliers til en vektor og fjerner dem
outliers <- boxplot(ROAS, plot=FALSE)$out
# fjerner rækker der indeholder outliers
KAG_conversion_data_nomiss_nooutliers <-
KAG_conversion_data_nomiss[-which(ROAS %in% outliers),]
boxplot(KAG_conversion_data_nomiss_nooutliers$ROAS)
# Der eksisterer alternative måder at behandle outliers.
# Okay, nu er navnet blevet for langt:)
KAG_bts <-
KAG_conversion_data_nomiss_nooutliers
# Der eksisterer alternative måder at behandle outliers.
# Okay, nu er navnet blevet for langt:)
KAG_bts <-
KAG_conversion_data_nomiss_nooutliers
KAG_bts <- KAG_bts %>% select(ROAS, everything())
x <- model.matrix(ROAS ~ ., KAG_bts)[, -1]
y <- KAG_bts$ROAS
set.seed(123)
train <- sample(1:nrow(x), nrow(x)*2/3)
test <- (-train)
y.test <- y[test]
#best subset
predict.regsubsets <- function(object, newdata, id, ...) {
form <- as.formula(object$call[[2]])
mat <- model.matrix(form, newdata)
coefi <- coef(object, id = id)
xvars <- names(coefi)
mat[, xvars] %*% coefi
}
KAG_train <- KAG_bts[train,]
KAG_test <- KAG_bts[test,]
k <- 10 # Vi danner 10 folds
n <- nrow(KAG_bts) # registrerer hvor mange observationer, vi har.
set.seed(123)
folds <- sample(rep(1:k, length = n)) #Vi tildeler en værdi mellem 1 og n
dim(KAG_train)[2]  # Der er 20 variabler og dermed 19 prædiktorer
cv.errors <- matrix(NA, k, 19,
dimnames = list(NULL, paste(1:19)))
cv.errors
str(KAG_bts)
View(KAG_bts)
for (j in 1:k) { # her gennemløbes alle folds
best.fit <- regsubsets(ROAS ~ .,
data = KAG_train[folds != j, ],
nvmax = 19)
for (i in 1:19) { # her gennemløbes alle kandidatmodeller
pred <- predict(best.fit, KAG_train[folds == j, ], id = i)
# predict-funktionen ovenfor kalder den funktion, vi har lavet tidligere.
cv.errors[j, i] <-
mean((KAG_train$ROAS[folds == j] - pred)^2) # Her udregnes MSE for hver
# fold for hver kandidatmodel
}
}
View(KAG_bts)
library(leaps)
library(dplyr)
# Forberedelse af data
x <- model.matrix(ROAS ~ ., KAG_bts)[, -1]
y <- KAG_bts$ROAS
set.seed(123)
train_indices <- sample(1:nrow(x), nrow(x)*2/3)
test_indices <- setdiff(1:nrow(x), train_indices)
y.test <- y[test_indices]
# Tilpasning af den brugerdefinerede predict funktion til regsubsets
predict.regsubsets <- function(object, newdata, id, ...) {
form <- as.formula(object$call[[2]])
mat <- model.matrix(form, newdata)
coefi <- coef(object, id = id)
xvars <- names(coefi)
mat[, xvars, drop = FALSE] %*% coefi
}
# Opretter trænings- og testdatasæt
KAG_train <- KAG_bts[train_indices,]
KAG_test <- KAG_bts[test_indices,]
# Initialisering af krydsvalidering
k <- 10 # Antal folds
n <- nrow(KAG_train) # Antal observationer i træningssættet
set.seed(123)
folds <- sample(rep(1:k, length = n)) # Tilfældig tildeling af folds
# Forbered matrix til krydsvalideringsfejl
cv.errors <- matrix(NA, k, 19, dimnames = list(NULL, paste(1:19)))
for (j in 1:k) { # Gennemgår alle folds
fold_train <- KAG_train[folds != j, ]
fold_test <- KAG_train[folds == j, ]
best.fit <- regsubsets(ROAS ~ ., data = fold_train, nvmax = 19)
for (i in 1:19) { # Gennemgår alle kandidatmodeller
pred <- predict(best.fit, newdata = fold_test, id = i)
actual <- KAG_train$ROAS[folds == j]
# Beregner MSE for hver fold og hver model
cv.errors[j, i] <- mean((actual - pred)^2)
}
}
# Korrektion for opsætning af train/test indekser
set.seed(123)
n <- nrow(KAG_bts)
train <- sample(1:n, n*2/3)
test <- setdiff(1:n, train)
KAG_train <- KAG_bts[train,]
KAG_test <- KAG_bts[test,]
# Forbereder krydsvalidering
k <- 10 # Antal folds
folds <- sample(rep(1:k, length.out = n)) # Tildeler hver observation til en fold
cv.errors <- matrix(NA, k, 19, dimnames = list(NULL, paste0("Model ", 1:19)))
# Kører krydsvalidering
for (j in 1:k) {
fold_train <- KAG_train[folds[train] != j, ] # Bruger 'folds[train]' til at sikre, at vi kun bruger træningsdata
fold_test <- KAG_train[folds[train] == j, ]
best.fit <- regsubsets(ROAS ~ ., data = fold_train, nvmax = 19)
for (i in 1:19) {
# Tjekker om det valgte modelnummer (i) er inden for antallet af modeller genereret
if(i <= length(best.fit$nvmax)) {
pred <- predict(best.fit, newdata = fold_test, id = i)
actual <- fold_test$ROAS
# Beregner MSE for hver fold og hver model
cv.errors[j, i] <- mean((actual - pred)^2)
} else {
cv.errors[j, i] <- NA # Sætter NA, hvis modellen ikke eksisterer
}
}
}
set.seed(123)
n <- nrow(KAG_train) # Antal observationer i træningsdatasættet
k <- 10 # Antal folds
folds <- sample(rep(1:k, length.out = n)) # Tildeler hver observation en fold
cv.errors <- matrix(NA, nrow = k, ncol = 19, dimnames = list(NULL, paste(1:19))) # Forbereder en matrix til at holde krydsvalideringsfejl
for (j in 1:k) { # Gennemgår alle folds
fold_train <- KAG_train[folds != j, ] # Træningsdata for den aktuelle fold
fold_test <- KAG_train[folds == j, ] # Testdata for den aktuelle fold
best.fit <- regsubsets(ROAS ~ ., data = fold_train, nvmax = 19) # Fitter modellen på foldens træningsdata
for (i in 1:19) { # Gennemgår alle potentielle modelstørrelser
# Kontrollerer om det specifikke subset af modellen (givet ved i) er tilladt givet den faktiske model størrelse
if(i <= max(best.fit$nvmax)) {
pred <- predict(best.fit, newdata = fold_test, id = i) # Foretager forudsigelser med den i'te model
actual <- fold_test$ROAS # Faktiske værdier
# Beregner og gemmer mean squared error for den aktuelle fold og modelstørrelse
cv.errors[j, i] <- mean((actual - pred)^2)
} else {
cv.errors[j, i] <- NA # Håndterer tilfælde, hvor en modelstørrelse ikke er tilgængelig
}
}
}
# Udskriv den opdaterede cv.errors for at se resultaterne
print(cv.errors)
setwd("C:/Users/mette/OneDrive/Skrivebord/Bankchurn")
pacman::p_load("tidyverse", "magrittr", "nycflights13", "gapminder",
"Lahman", "maps", "lubridate", "pryr", "hms", "hexbin",
"feather", "htmlwidgets", "broom", "pander", "modelr",
"XML", "httr", "jsonlite", "lubridate", "microbenchmark",
"splines", "ISLR2", "MASS", "testthat", "leaps", "caret",
"RSQLite", "class", "babynames", "nasaweather", "pls",
"fueleconomy", "viridis", "boot", "devtools", "tree",
"glmnet", "gam", "akima")
attach(Wage)
pacman::p_load("tidyverse", "magrittr", "nycflights13", "gapminder",
"Lahman", "maps", "lubridate", "pryr", "hms", "hexbin",
"feather", "htmlwidgets", "broom", "pander", "modelr",
"XML", "httr", "jsonlite", "lubridate", "microbenchmark",
"splines", "ISLR2", "MASS", "testthat", "leaps", "caret",
"RSQLite", "class", "babynames", "nasaweather", "pls",
"fueleconomy", "viridis", "boot", "devtools", "tree",
"glmnet", "gam", "akima")
attach(Wage)
